{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Detection in Chest X-Ray Images\n",
    "The goal of this project is to build a model that identifies COVID-19, pneumonia in chest X-Ray images. The dataset is organized into 3 folders (COVID-19 cases, Normal , Pneumonia) and contains subfolders for each image category. There are 606 X-Ray images (JPEG). Data from [Mendeley](https://data.mendeley.com/datasets/fvk7h5dg2p/1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import requests\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "roboflow_api_key = os.getenv(\"ROBOFLOW_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"dataroot/\"\n",
    "zip_path = dataroot + \"fvk7h5dg2p-1.zip\"\n",
    "raw_path = dataroot + \"raw/\"\n",
    "\n",
    "def download_data(url):\n",
    "    '''\n",
    "    Creates a directory nammed 'dataroot' and downloads the zip file from the url and saves the zip file\n",
    "    to the 'dataroot' folder.\n",
    "    '''\n",
    "    response = requests.get(url, params={\"downloadformat\": \"zip\"})\n",
    "    if not os.path.isdir(dataroot):\n",
    "        os.makedirs(dataroot)\n",
    "        with open(zip_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "\n",
    "def unzip_data():\n",
    "    if os.path.isdir(dataroot):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            for file in zip_ref.namelist():\n",
    "                sanitized_name = file.strip().replace(\"\\\\\", \"/\") #Ensure consistent path format\n",
    "                #Sanitize folder name for \"Normal \"\n",
    "                if sanitized_name.startswith(\"Normal \"):\n",
    "                    sanitized_name = sanitized_name.replace(\"Normal \", \"Normal\", 1)\n",
    "                if sanitized_name.startswith(\"COVID-19\"):\n",
    "                    sanitized_name = sanitized_name.replace(\"COVID-19 cases\", \"COVID-19\", 1)\n",
    "            \n",
    "                #Create the full target path within the 'Normal' folder\n",
    "                target_path = os.path.join(raw_path, sanitized_name)\n",
    "\n",
    "                #Skip directories (avoid trying to open them as files)\n",
    "                if file.endswith(\"/\"):\n",
    "                    os.makedirs(target_path, exist_ok=True)\n",
    "                    continue\n",
    "            \n",
    "                #Ensure the parent directory exists before extracting\n",
    "                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "\n",
    "                # Extract file safely\n",
    "                with zip_ref.open(file) as source, open(target_path, \"wb\") as target:\n",
    "                    target.write(source.read())\n",
    "\n",
    "        os.remove(zip_path) # Remove zip file\n",
    "        print(\"Extraction completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataroot already exists.\n"
     ]
    }
   ],
   "source": [
    "# Download and unzip\n",
    "if not os.path.isdir(dataroot):\n",
    "    download_data(\"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/fvk7h5dg2p-1.zip\")\n",
    "    unzip_data()\n",
    "else:\n",
    "    print(\"dataroot already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning with roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R0Fmr5AjCMpkbtaADUzd\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "#Connecting to the model on roboflow\n",
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.workspace().project(\"cap-project-u384k\")\n",
    "model = project.version(1).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg = cv2.imread(\"/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg\")\\nresult = model.predict(img, confidence=20, overlap=30).json()\\nfor i in range(len(result[\\'predictions\\'])):\\n    prediction = result[\\'predictions\\'][i]\\n    roi_x = int(prediction[\\'x\\'] - prediction[\\'width\\']/2)\\n    roi_y = int(prediction[\\'y\\'] - prediction[\\'height\\']/2)\\n    roi_width = int(prediction[\\'width\\'])\\n    roi_height = int(prediction[\\'height\\'])\\n    img[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = 0\\n\\ncv2_imshow(img)\\nblack_mask = np.all(img == 0, axis=-1)\\nalpha = np.uint8(np.logical_not(black_mask)) * 255\\nbgra = np.dstack((img, alpha))\\ncv2_imshow(bgra)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_x_rays(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for item in os.walk(input_folder):\n",
    "        root = item[0]\n",
    "        files = item[2]\n",
    "        for file in files:\n",
    "            img = cv.imread(os.path.join(root, file))\n",
    "            result = model.predict(img, confidence=20, overlap=30).json()\n",
    "            for i in range(len(result['predictions'])):\n",
    "                prediction = result['predictions'][i]\n",
    "                roi_x = int(prediction['x'] - prediction['width']/2)\n",
    "                roi_y = int(prediction['y'] - prediction['height']/2)\n",
    "                roi_width = int(prediction['width'])\n",
    "                roi_height = int(prediction['height'])\n",
    "                img[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = 0\n",
    "            cv.imwrite(os.path.join(output_folder, file), img)\n",
    "\n",
    "\n",
    "clean_path = dataroot + \"cleaned/\"\n",
    "clean_x_rays(r\"dataroot\\COVID-19\", clean_path + \"COVID-19\")\n",
    "clean_x_rays(r\"dataroot\\Normal\", clean_path + \"Normal\")\n",
    "clean_x_rays(r\"dataroot\\Pneumonia\", clean_path + \"Pneumonia\")\n",
    "\n",
    "'''\n",
    "img = cv2.imread(\"/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg\")\n",
    "result = model.predict(img, confidence=20, overlap=30).json()\n",
    "for i in range(len(result['predictions'])):\n",
    "    prediction = result['predictions'][i]\n",
    "    roi_x = int(prediction['x'] - prediction['width']/2)\n",
    "    roi_y = int(prediction['y'] - prediction['height']/2)\n",
    "    roi_width = int(prediction['width'])\n",
    "    roi_height = int(prediction['height'])\n",
    "    img[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = 0\n",
    "\n",
    "cv2_imshow(img)\n",
    "black_mask = np.all(img == 0, axis=-1)\n",
    "alpha = np.uint8(np.logical_not(black_mask)) * 255\n",
    "bgra = np.dstack((img, alpha))\n",
    "cv2_imshow(bgra)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_covid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_normal,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\School\\Master's Program\\Capstone\\ChestXRayClassifier\\venv\\lib\\site-packages\\matplotlib\\pyplot.py:3590\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   3568\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   3569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   3570\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[1;32m-> 3590\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   3591\u001b[0m         X,\n\u001b[0;32m   3592\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[0;32m   3593\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   3594\u001b[0m         aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   3595\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   3596\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m   3597\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   3598\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[0;32m   3599\u001b[0m         colorizer\u001b[38;5;241m=\u001b[39mcolorizer,\n\u001b[0;32m   3600\u001b[0m         origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   3601\u001b[0m         extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   3602\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   3603\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   3604\u001b[0m         filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[0;32m   3605\u001b[0m         resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   3606\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   3607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3608\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3609\u001b[0m     )\n\u001b[0;32m   3610\u001b[0m     sci(__ret)\n\u001b[0;32m   3611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32me:\\School\\Master's Program\\Capstone\\ChestXRayClassifier\\venv\\lib\\site-packages\\matplotlib\\__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m   1522\u001b[0m             ax,\n\u001b[0;32m   1523\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(cbook\u001b[38;5;241m.\u001b[39msanitize_sequence, args),\n\u001b[0;32m   1524\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: cbook\u001b[38;5;241m.\u001b[39msanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32me:\\School\\Master's Program\\Capstone\\ChestXRayClassifier\\venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5976\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5976\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5977\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5979\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[1;32me:\\School\\Master's Program\\Capstone\\ChestXRayClassifier\\venv\\lib\\site-packages\\matplotlib\\image.py:685\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    684\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\School\\Master's Program\\Capstone\\ChestXRayClassifier\\venv\\lib\\site-packages\\matplotlib\\image.py:648\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    646\u001b[0m A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    651\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preview images\n",
    "dataroot = \"dataroot/\"\n",
    "img_covid     = cv.imread(dataroot+'COVID-19/1-s2.0-S0929664620300449-gr2_lrg-d.jpg',0)\n",
    "img_normal    = cv.imread(dataroot+'Normal/IM-0011-0001-0001.jpeg',0)\n",
    "img_pneumonia = cv.imread(dataroot+'Pneumonia/person11_virus_38.jpeg',0)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img_covid,cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_normal,cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_pneumonia,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for preprocessing the x-rays and then returning images and their labels for creating a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xray(img, resize_shape=(512, 512)):\n",
    "    \"\"\"\n",
    "    Converts the image to grayscale if needed, resizes it, and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to grayscale if needed\n",
    "    if len(img.shape) == 3:\n",
    "        gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_img = img.copy()\n",
    "\n",
    "    # Resize and normalize\n",
    "    resized = cv.resize(gray_img, resize_shape)\n",
    "    normalized = resized.astype(np.float32) / 255.0\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def load_and_process_images(base_dir, resize_shape=(512, 512)):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses images from subdirectories in the given base directory.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): Path to the directory containing class subfolders.\n",
    "        resize_shape (tuple): Desired image size (width, height) for resizing.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Arrays of processed images and their corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(base_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            file_path = os.path.join(class_dir, file_name)\n",
    "            img = cv.imread(file_path)\n",
    "            if img is not None:\n",
    "                processed = preprocess_xray(img, resize_shape)\n",
    "                images.append(processed)\n",
    "                labels.append(class_name)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get images and labels, put flattened images and labels into a df, then split into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_and_process_images(dataroot)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"image\": [img.flatten() for img in images],\n",
    "    \"label\": labels\n",
    "})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df[\"image\"].tolist()), df[\"label\"], test_size=0.2, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'n_estimators': [50, 100, 150, 200, 250]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf, \n",
    "    param_grid=param_grid,\n",
    "    cv=5, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(f\"\\nOptimal F1-macro score:: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)   \n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
